{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a99ce7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1 align=\"center\">Information Retrival Systems</h1>\n",
    "    <h2 align=\"center\">Simple search engine project</h2>\n",
    "    <h3 align=\"center\">Phase 2</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3730253",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20211b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsivar import Normalizer, Tokenizer, FindStems\n",
    "from hazm import stopwords_list\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0370506",
   "metadata": {},
   "source": [
    "## Loading raw and processed Data\n",
    "- loading the json file as a dataframe and also transpose it\n",
    "- loading preprocessed content\n",
    "- loading inverted index\n",
    "- create dictionary according to inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "533e152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('IR_data_news_12k.json')\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47827ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    my_file = None\n",
    "    with open(filename, 'rb') as inp:\n",
    "        my_file = pickle.load(inp)\n",
    "    return my_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5362613",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_content = load_file('./Processed data/preprocessed_content.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d85a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = load_file('./Processed data/inverted_index.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04483769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = list(inverted_index.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7998678",
   "metadata": {},
   "source": [
    "# Step1)\n",
    "## Modeling documents in vector space\n",
    "- Here we should define a function that calculate tf_idf score. The formula explained below:\n",
    "$$tfidf(t, d, D) = tf(t, d) \\times idf(t, D) = \\ (1 + log(f_{t, d})) \\times \\log(\\frac{N}{n_t})$$    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "579c8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(term, doc, doc_collection, total_number_of_docs):\n",
    "    # idf is a constant value for each token and it doesnt depend on query\n",
    "    N = total_number_of_docs\n",
    "    nt = doc_collection[term]['doc_frequency']\n",
    "    idf = math.log10(N / nt)\n",
    "    \n",
    "    # now we should compute number of term in that doc\n",
    "    term_count = doc.count(term)\n",
    "    if term_count == 0:\n",
    "        tf = 0\n",
    "    else:\n",
    "        tf = 1+math.log10(term_count)\n",
    "    \n",
    "    return  tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d076490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007249774608743844\n"
     ]
    }
   ],
   "source": [
    "print(tfidf('خبرگزاری',df.iloc[3]['content'], inverted_index , len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e5633",
   "metadata": {},
   "source": [
    "# Step2)\n",
    "## Answering the queries in the vector space  \n",
    "\n",
    "- Here we should define a function for calculating cosine similarity. Also we define a function to compute Doc_length.\n",
    "- For this part we help from pseudo code in slides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf449d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(doc_id):\n",
    "    l = 0\n",
    "    for token in preprocessed_content[doc_id]:\n",
    "        l += tfidf(term=token, doc=preprocessed_content[doc_id], doc_collection=inverted_index, total_number_of_docs=len(df))**2\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79622daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(query, k, inverted_index, is_champion=True):\n",
    "    docID_score = {}\n",
    "    doc_ids = []\n",
    "    for term in query:\n",
    "        # step 1: calculate weight of term in the query\n",
    "        weight_in_query = tfidf(term=term, doc=query, doc_collection=inverted_index, total_number_of_docs=len(df))\n",
    "        # step 2: get postings list for term (if is_champion is true we should use ch)\n",
    "        if is_champion:\n",
    "            postings_list = inverted_index[term]['champion']\n",
    "        else:\n",
    "            postings_list = inverted_index[term]['posting_list']\n",
    "            \n",
    "        for posting in postings_list:\n",
    "            if is_champion:\n",
    "                doc_id = posting[0]\n",
    "            else:\n",
    "                doc_id = list(posting.keys())[0]\n",
    "            # step 3: calculate weight of term in the Doc\n",
    "            weight_in_doc = tfidf(term=term, doc=df.iloc[doc_id]['content'],  doc_collection=inverted_index, total_number_of_docs=len(df))\n",
    "            \n",
    "            # step4:save or update related score of a doc\n",
    "            if docID_score.get(doc_id):\n",
    "                docID_score[doc_id]['score'] += weight_in_query * weight_in_doc\n",
    "                #docID_score[doc_id]['squar length'] += (weight_in_doc ** 2)\n",
    "            else:\n",
    "                doc_ids.append(doc_id)\n",
    "                #docID_score[doc_id]= {'squar length': weight_in_doc ** 2, 'score':weight_in_query * weight_in_doc}\n",
    "                docID_score[doc_id]= {'squar length': get_length(doc_id), 'score':weight_in_query * weight_in_doc}\n",
    "    # step5: normalizing\n",
    "    new_docID_score = []\n",
    "    for doc_id in doc_ids:\n",
    "        docID_score[doc_id]['score'] = docID_score[doc_id]['score']/math.sqrt(docID_score[doc_id]['squar length'])\n",
    "        new_docID_score.append((doc_id,docID_score[doc_id]['score']))\n",
    "    # step6: select k best:\n",
    "    new_docID_score = [(docID_score[0],docID_score[1]['score']) for docID_score in docID_score.items()]\n",
    "    if k > len(new_docID_score):\n",
    "        k = len(new_docID_score)\n",
    "    k_best = []\n",
    "    for i in range(k):\n",
    "        max_score = max(new_docID_score,key=lambda x:x[1])\n",
    "        k_best.append(max_score)\n",
    "        new_docID_score.remove(max_score)\n",
    "    return k_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cd24e",
   "metadata": {},
   "source": [
    "# Step3)\n",
    "## Increasing the speed of processing of queries\n",
    "- In this section we should define a function to copy prevoius inverted index and add **champion lists** to our new inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "113668c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_champions(r):\n",
    "    index_with_champion = inverted_index\n",
    "    for token in index_with_champion:\n",
    "        new_docID_tf = []\n",
    "        for posting in index_with_champion[token]['posting_list']:\n",
    "            new_docID_tf.append((list(posting.keys())[0], posting[list(posting.keys())[0]]['term_frequency']))\n",
    "            \n",
    "        inverted_index[token]['champion'] = []\n",
    "        \n",
    "        if r>len(inverted_index[token]['posting_list']):\n",
    "            r= len(inverted_index[token]['posting_list'])\n",
    "            \n",
    "        for i in range(r):\n",
    "            max_tf = max(new_docID_tf,key=lambda x:x[1])\n",
    "            inverted_index[token]['champion'].append(max_tf)\n",
    "            new_docID_tf.remove(max_tf)    \n",
    "    return index_with_champion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ca87e",
   "metadata": {},
   "source": [
    "- So we can call above function to create champion lists. each list just has r postings or less. I consider r equal to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6268a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_with_champion = create_champions(r = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be680bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11604, 31), (11449, 30), (9500, 29), (11163, 28), (11774, 26), (11686, 25)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_with_champion['گزارش']['champion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21da8646",
   "metadata": {},
   "source": [
    "- now we can define a function to show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d88b0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(results):\n",
    "    if len(results)==0:\n",
    "        print(\"There isn't any doc related to this query\")\n",
    "    else:\n",
    "        for result in results:\n",
    "            print(50* \"/\\\\\")\n",
    "            print(f'docID: {result[0]}')\n",
    "            print(f'Score: {result[1]}')\n",
    "            print(f'Title: {df.loc[result[0]][\"title\"]}')\n",
    "            print(f'URL: {df.loc[result[0]][\"url\"]}')\n",
    "            print(f'{df.loc[result[0]][\"content\"]}')\n",
    "            print(50*\"/\\\\\")               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02032722",
   "metadata": {},
   "source": [
    "- also we need an interface that get user query and then show related results to him. I cosider k equal to 5. it means it only returns the first k that have the most score among the champion list or in posting list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97172617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, is_champion):\n",
    "    preprocessed_query = total_preprocess(query)\n",
    "    new_query = []\n",
    "    for term in preprocessed_query:\n",
    "        if term in dictionary:\n",
    "            new_query.append(term)\n",
    "    k_best = []\n",
    "    if is_champion:\n",
    "        k_best = cosine(query=new_query, k=5, inverted_index=index_with_champion, is_champion=is_champion)\n",
    "    else:\n",
    "        k_best = cosine(query=new_query, k=5, inverted_index=inverted_index, is_champion=is_champion)\n",
    "        \n",
    "    show_result(k_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798125cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
